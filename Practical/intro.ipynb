{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('trestle_academy_dataset.csv')\n",
    "# first five rows\n",
    "\n",
    "# df.head()\n",
    "# df.info\n",
    "# df.describe()\n",
    "# df.columns\n",
    "# df.isnull()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'messy.txt'\n",
    "\n",
    "# r = read file\n",
    "# w = write to file\n",
    "# r+ = read/write file\n",
    "# a = append to file\n",
    "\n",
    "\n",
    "# with open(filename, 'r') as file:\n",
    "#     file_data = file.read()\n",
    "#     print(file_data)\n",
    "\n",
    "\n",
    "# wriet to a file \n",
    "filename =  'write_file.txt'\n",
    "# with open(filename, 'w') as file:\n",
    "#     file_data = file.write('Today is an.')\n",
    "\n",
    "\n",
    "with open(filename, 'a') as file:\n",
    "    file_data = file.write('\\nWe have appended a new line\\n')\n",
    "    file_data = file.write('Writing new one again\\n')\n",
    "    file_data = file.write('Writing new one again\\n')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>1700</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     country   1700\n",
       "0      False  False\n",
       "1      False  False\n",
       "2      False  False\n",
       "3      False  False\n",
       "4      False  False\n",
       "..       ...    ...\n",
       "241    False  False\n",
       "242    False   True\n",
       "243    False  False\n",
       "244    False  False\n",
       "245    False  False\n",
       "\n",
       "[246 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('latitude.xls')\n",
    "\n",
    "df.head()\n",
    "df.info\n",
    "df.describe()\n",
    "df.columns\n",
    "df.isnull()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>course</th>\n",
       "      <th>enrollment_date</th>\n",
       "      <th>final_grade</th>\n",
       "      <th>is_intern</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     student_id   name    age  gender  course  enrollment_date  final_grade  \\\n",
       "0         False   True   True   False   False            False        False   \n",
       "1         False  False  False   False   False            False         True   \n",
       "2         False  False  False   False   False            False        False   \n",
       "3         False  False  False   False    True            False        False   \n",
       "4         False  False  False   False   False            False        False   \n",
       "..          ...    ...    ...     ...     ...              ...          ...   \n",
       "995       False  False  False   False   False            False        False   \n",
       "996       False  False  False   False   False            False        False   \n",
       "997       False  False  False   False   False            False        False   \n",
       "998       False  False  False   False   False            False        False   \n",
       "999       False  False  False   False   False            False        False   \n",
       "\n",
       "     is_intern  \n",
       "0        False  \n",
       "1        False  \n",
       "2        False  \n",
       "3        False  \n",
       "4        False  \n",
       "..         ...  \n",
       "995      False  \n",
       "996      False  \n",
       "997      False  \n",
       "998      False  \n",
       "999      False  \n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missin values\n",
    "import pandas as pd \n",
    "data = pd.read_csv('trestle_academy_dataset.csv')\n",
    "data.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'age' in data.columns and data['age'].isnull().sum() > 0:\n",
    "    average_age = data['age'].mean()\n",
    "    data['age'].fillna(average_age, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking for missing values:\n",
      "country    0\n",
      "1700       4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 2. Handle Missing Values\n",
    "# Check for any missing values in each column\n",
    "print(\"\\nChecking for missing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "#incase there might be some missing values in 'age' or 'final_grade'\n",
    "# Fill missing 'age' with the mean age\n",
    "if 'age' in df.columns and df['age'].isnull().sum() > 0:\n",
    "    mean_age = df['age'].mean()\n",
    "    df['age'].fillna(mean_age, inplace=True)\n",
    "    print(f\"Filled missing values in 'age' with mean age: {mean_age}\")\n",
    "\n",
    "    # Fill missing 'final_grade' with median grade\n",
    "if 'final_grade' in df.columns and df['final_grade'].isnull().sum() > 0:\n",
    "    median_grade = df['final_grade'].median()\n",
    "    df['final_grade'].fillna(median_grade, inplace=True)\n",
    "    print(f\"Filled missing values in 'final_grade' with median grade: {\n",
    "          median_grade}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "IntCastingNaNError",
     "evalue": "Cannot convert non-finite values (NA or inf) to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIntCastingNaNError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_grade\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfinal_grade\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menrollment_date\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menrollment_date\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\ishma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:6534\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6530\u001b[0m     results \u001b[38;5;241m=\u001b[39m [ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()]\n\u001b[0;32m   6532\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6533\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6534\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6535\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m   6536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ishma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:414\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    412\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 414\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    420\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ishma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:354\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 354\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    355\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    357\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32mc:\\Users\\ishma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:616\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors, using_cow)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    597\u001b[0m \u001b[38;5;124;03mCoerce to the new dtype.\u001b[39;00m\n\u001b[0;32m    598\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[38;5;124;03mBlock\u001b[39;00m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    614\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m--> 616\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    618\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    620\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ishma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:238\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    235\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 238\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\ishma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:183\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    180\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 183\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\ishma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:101\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mensure_string_array(\n\u001b[0;32m     97\u001b[0m         arr, skipna\u001b[38;5;241m=\u001b[39mskipna, convert_na_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     98\u001b[0m     )\u001b[38;5;241m.\u001b[39mreshape(shape)\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(arr\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mfloating) \u001b[38;5;129;01mand\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_astype_float_to_int_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;66;03m# if we have a datetime/timedelta array of objects\u001b[39;00m\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;66;03m# then coerce to datetime64[ns] and use DatetimeArray.astype\u001b[39;00m\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mis_np_dtype(dtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\ishma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:146\u001b[0m, in \u001b[0;36m_astype_float_to_int_nansafe\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;124;03mastype with a check preventing converting NaN to an meaningless integer value.\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(values)\u001b[38;5;241m.\u001b[39mall():\n\u001b[1;32m--> 146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IntCastingNaNError(\n\u001b[0;32m    147\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot convert non-finite values (NA or inf) to integer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    148\u001b[0m     )\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;66;03m# GH#45151\u001b[39;00m\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (values \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mall():\n",
      "\u001b[1;31mIntCastingNaNError\u001b[0m: Cannot convert non-finite values (NA or inf) to integer"
     ]
    }
   ],
   "source": [
    "data['age'] = data['age'].astype(int)\n",
    "data['final_grade'] = data['final_grade'].astype(int)\n",
    "data['enrollment_date'] = pd.to_datetime(data['enrollment_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: 2024-11-12\n",
      "Time: 07:40:11 PM\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "date = dt.datetime.today()\n",
    "\n",
    "date = dt.datetime.today().strftime('%Y-%m-%d')\n",
    "print('Date:',date)\n",
    "\n",
    "time = dt.datetime.today().strftime('%I:%M:%S %p')\n",
    "print('Time:', time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. Standardize Data Types\n",
    "# Ensure 'age' and 'final_grade' are integers, 'enrollment_date' is a date\n",
    "df['age'] = df['age'].astype(int)\n",
    "df['final_grade'] = df['final_grade'].astype(int)\n",
    "df['enrollment_date'] = pd.to_datetime(df['enrollment_date'])\n",
    "# check whether age, finally_grade and enrollment_date has been updated to int\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Normalize Text Data\n",
    "# Convert text in 'course' and 'gender' to title case for consistency\n",
    "df['course'] = df['course'].str.title()\n",
    "df['gender'] = df['gender'].str.title()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5. Filter Unwanted Data\n",
    "# Filter out rows where 'age' is outside the student age range (18 to 45)\n",
    "df = df[|(df['age'] >= 18)| & (df['age'] <= 45)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Correct Inconsistent Entries\n",
    "# Standardize 'is_intern' column to have consistent 'Yes'/'No' values\n",
    "# We will use a for loop instead \n",
    "\n",
    "# Convert inconsistent entries in 'is_intern' to 'Yes' or 'No'\n",
    "for i in range(len(df['is_intern'])):\n",
    "    # Convert value to lowercase for consistency\n",
    "    value = str(df.loc[i, 'is_intern']).lower()\n",
    "    if value in ['yes', 'y', 'true', '1']:\n",
    "        df.loc[i, 'is_intern'] = 'Yes'\n",
    "    else:\n",
    "        df.loc[i, 'is_intern'] = 'No'\n",
    "\n",
    "print(\"\\nStandardized 'is_intern' column values:\")\n",
    "print(df['is_intern'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 7. Save the Cleaned Data\n",
    "# Save the cleaned dataset to a new file for pipeline ingestion\n",
    "cleaned_dataset_path = 'cleaned_trestle_academy_dataset.csv'\n",
    "df.to_parquet(cleaned_dataset_path, index=False)\n",
    "print(f\"\\nCleaned dataset saved to {cleaned_dataset_path}\")\n",
    "\n",
    "# Final confirmation of cleaned data\n",
    "print(\"\\nCleaned Data Preview:\")\n",
    "print(df.head())\n",
    "print(\"\\nCleaned Data Summary:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using loc \n",
    "import pandas as pd\n",
    "df = pd.read_csv('trestle_academy_dataset.csv')\n",
    "data = df.loc[:, ['student_id', 'course', 'final_grade']]\n",
    "new_data = data.to_csv('new_student.csv', index=False)\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id, course, final_grade >= 80\n",
    "data = df.loc[(df['final_grade'] >= 80), [\n",
    "    'student_id', 'course', 'final_grade']]\n",
    "\n",
    "passed_students = data.to_csv('passed_students.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('passed_students.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "filename = 'titanic.csv'\n",
    "data = pd.read_csv(filename)\n",
    "data['Fare'] = round(data['Fare'], 2)\n",
    "# data['Fare'] = data['Age'].astype('Fare')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd  \n",
    "engine = create_engine('sqlite:///Northwind.sqlite')\n",
    "con = engine.connect()\n",
    "query = con.execute(\"SELECT * FROM Orders\")\n",
    "df = pd.DataFrame(query.fetchall())\n",
    "con.close()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('articles.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORKING WITH API USING ENVIRONMENTA VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as r\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the API key from environment variables\n",
    "api_key = os.getenv('API_KEY')\n",
    "\n",
    "url = 'https://newsapi.org/v2/top-headlines'\n",
    "params = {'country': 'gr'}\n",
    "headers = {'Authorization': f'Bearer {api_key}'}\n",
    "\n",
    "response = r.get(url, params=params, headers=headers)\n",
    "data = response.json()\n",
    "for article in data['articles']:\n",
    "    print(article.get('title'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve as r\n",
    "import pandas as pd\n",
    "url = 'https://assets.datacamp.com/production/course_1606/datasets/winequality-red.csv'\n",
    "response = r(url, 'winequality-red.csv')\n",
    "df = pd.read_csv('winequality-red.csv', sep=';')\n",
    "columns = df.columns\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import package\n",
    "import pandas as pd\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "# Assign url of file: url\n",
    "url = 'https://assets.datacamp.com/course/importing_data_into_r/latitude.xls'\n",
    "urlretrieve(url, 'latitude.xls')\n",
    "\n",
    "# Read in all sheets of Excel file: xls\n",
    "xls = pd.read_excel('latitude.xls', sheet_name=None)\n",
    "\n",
    "# Print the sheetnames to the shell\n",
    "print(xls.keys())\n",
    "\n",
    "# Print the head of the first sheet (using its name, NOT its index)\n",
    "print(xls['1700'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as r \n",
    "url = \"https://campus.datacamp.com/courses/1606/4135?ex=2\"\n",
    "response = r.get(url)\n",
    "response_text = response.text\n",
    "print(response_text)\n",
    "\n",
    "# YOU CAN PLAY WITH THIS MORE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as BS\n",
    "import requests as r \n",
    "\n",
    "url = \"https://www.billboard.com/pro/indie-labels-own-half-recorded-music-market-midia-report/\"\n",
    "response = r.get(url)\n",
    "html_doc = response.text\n",
    "soup = BS(html_doc, 'html.parser')  # Specify parser for better consistency\n",
    "\n",
    "titles = soup.find_all('title')\n",
    "filename = 'blog.txt'\n",
    "\n",
    "# Open file and write each title to a new line\n",
    "with open(filename, 'a') as file:\n",
    "    for title in titles:\n",
    "        file.write(title.text + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "# Load the data\n",
    "data = pd.read_csv('titanic.csv')\n",
    "\n",
    "\n",
    "# Calculate summary statistics and add them as new columns\n",
    "data['Average_Age'] = data['Age'].mean()\n",
    "data['Max_Age'] = data['Age'].max()\n",
    "data['Min_Age'] = data['Age'].min()\n",
    "\n",
    "data['Average_Fare'] = round(data['Fare'].mean(), 2)\n",
    "data['Max_Fare'] = data['Fare'].max()\n",
    "data['Min_Fare'] = data['Fare'].min()\n",
    "\n",
    "# add dates \n",
    "# get the time of today\n",
    "data['Date'] = dt.datetime.now().strftime('%Y-%m-%d')\n",
    "data['Time']= dt.datetime.now().strftime('%I:%M:%S %p')\n",
    "# Create a new DataFrame with only the new columns\n",
    "new_data = data[['Average_Age', 'Max_Age', 'Min_Age',\n",
    "                 'Average_Fare', 'Max_Fare', 'Min_Fare', 'Date', 'Time']].copy()\n",
    "``\n",
    "# Save the new DataFrame to a Parquet file\n",
    "new_data.to_csv('titanic_summary.csv', index=False)\n",
    "\n",
    "# Read the Parquet file to verify\n",
    "read_data = pd.read_csv('titanic_summary.csv')\n",
    "print(read_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('titanic.csv', nrows=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create boolean columns for each age group in the original DataFrame\n",
    "data['Children'] = data['Age'] < 13\n",
    "data['Adolescent'] = (data['Age'] >= 13) & (data['Age'] < 18)\n",
    "data['Adult'] = (data['Age'] >= 18) & (data['Age'] < 65)\n",
    "data['OldAge'] = data['Age'] >= 65\n",
    "\n",
    "# Check the first few rows to verify the new columns\n",
    "data[['Age', 'Children', 'Adolescent', 'Adult', 'OldAge']].copy()\n",
    "\n",
    "data.to_csv('Age_classification.csv', index=False)\n",
    "df = pd.read_csv('Age_classification.csv')\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "children = data[data['Age'] < 13]\n",
    "\n",
    "data['datetime'] = pd.to_datetime(data['Date']).dt.date\n",
    "\n",
    "for date in data['datetime']:\n",
    "    print(date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # BUILDING AN ETL PIPELINEB BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def extract(filename):\n",
    "    \"\"\"\n",
    "    Extract data from a file based on its extension.\n",
    "    \"\"\"\n",
    "    print(f\"Extracting data from '{filename}'...\\n\")\n",
    "    try:\n",
    "        if filename.endswith('.csv'):\n",
    "            return pd.read_csv(filename)\n",
    "        elif filename.endswith('.txt'):\n",
    "            with open(filename, 'r') as file_obj:\n",
    "                return pd.DataFrame([line.strip() for line in file_obj.readlines()], columns=['text'])\n",
    "        elif filename.endswith('.parquet'):\n",
    "            return pd.read_parquet(filename)\n",
    "        elif filename.endswith(('.xlsx', '.xls')):\n",
    "            return pd.read_excel(filename)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file type.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{filename}' does not exist.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def transform(dataframe):\n",
    "    \"\"\"\n",
    "    Transform the dataframe by selecting specific columns.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if {'student_id', 'name', 'course', 'final_grade'}.issubset(dataframe.columns):\n",
    "            dataframe = dataframe[['student_id',\n",
    "                                   'name', 'course', 'final_grade']]\n",
    "            return dataframe\n",
    "        else:\n",
    "            raise KeyError(\n",
    "                \"Missing one or more required columns: 'student_id', 'name', 'course', 'final_grade'\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during transformation: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def load(dataframe, save_filename):\n",
    "    \"\"\"\n",
    "    Load the dataframe into a CSV file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dataframe.to_csv(save_filename, index=False)\n",
    "        print(f\"Data successfully saved to '{save_filename}'.\")\n",
    "        return dataframe.head()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while saving the file: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the data \n",
    "extracting = extract('trestle_academy_dataset.csv')\n",
    "# Transforming the data \n",
    "transforming = transform(dataframe = extracting)\n",
    "#load and save data to csv\n",
    "load_data = load(dataframe = transforming, save_filename='trestle.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as r\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Define the API endpoint with query parameters and your API key\n",
    "\n",
    "url = 'https://newsapi.org/v2/top-headlines'\n",
    "\n",
    "params = {\n",
    "\n",
    "    'country': 'us',  # Articles from the United States\n",
    "\n",
    "    'category': 'technology',  # Technology-related articles\n",
    "\n",
    "    'q': 'AI',  # Articles that mention AI\n",
    "\n",
    "    'pageSize': 5,  # Get 5 articles per page\n",
    "\n",
    "    'page': 1,  # First page\n",
    "\n",
    "    'apiKey': 'e7811595ab0748339199934ed4a0cec3'  # Replace with your actual API key\n",
    "\n",
    "}\n",
    "\n",
    "# Make the request\n",
    "\n",
    "response = r.get(url, params=params)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    # Extract and structure the articles\n",
    "    articles = []\n",
    "    for article in data.get('articles', []):\n",
    "        articles.append({\n",
    "            \"Title\": article.get('title', 'N/A'),\n",
    "            \"Description\": article.get('description', 'N/A'),\n",
    "            \"URL\": article.get('url', 'N/A')\n",
    "        })\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame(articles)\n",
    "\n",
    "    # Adjust column order and formatting\n",
    "    df = df[[\"Title\", \"Description\", \"URL\"]].rename(columns={\n",
    "        \"Title\": \"ðŸ“° Title\",\n",
    "        \"Description\": \"ðŸ“ Description\",\n",
    "        \"URL\": \"ðŸ”— URL\"\n",
    "    })\n",
    "\n",
    "    # Show the DataFrame in a neat format\n",
    "    print(df.to_string(index=False))  # Suppress the index when printing\n",
    "\n",
    "    # Optionally save to a file for reference\n",
    "    df.to_csv(\"articles.csv\", index=False)\n",
    "\n",
    "    print(\"\\nData successfully saved to 'articles.csv'.\")\n",
    "else:\n",
    "    print(f\"Failed to fetch data: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE CODE ABOVE IS THE SAME IUS THE CODE  BELOW EXCEPT THAT, IT DOES NOT TRANSFORM THE COLUMNS  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "url = 'https://newsapi.org/v2/top-headlines'\n",
    "params = {\n",
    "    'country': 'us',\n",
    "    'category': 'technology',\n",
    "    'q': 'AI',\n",
    "    'apikey': 'e7811595ab0748339199934ed4a0cec3'\n",
    "}\n",
    "response = requests.get(url, params=params)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    articles = []\n",
    "    for article in data.get('articles'):\n",
    "        articles.append({\n",
    "            'Title': article.get('title', 'N/A'),\n",
    "            'Author': article.get('author', 'N/A'),\n",
    "            'Url': article.get('url', 'N/A'),\n",
    "            'Description': article.get('description', 'N/A')\n",
    "\n",
    "        })\n",
    "    df = pd.DataFrame(articles)\n",
    "    df.to_csv('articles.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions:\n",
    "\n",
    "# Select an API:\n",
    "Visit API List.fun or any other API directory. Choose an API that interests you.\n",
    "Example categories: Weather, Movies, Sports, Finance, or Fun APIs like jokes or quotes.\n",
    "\n",
    "# Explore the API Documentation:\n",
    "\n",
    "# Review the API documentation to understand its endpoints and available parameters.\n",
    "Familiarize yourself with how to customize parameters (e.g., query strings, filters, or date ranges).\n",
    "Extract Data:\n",
    "\n",
    "# Use Python to send a request to the API using the requests library.\n",
    "Customize the API parameters to fetch data you find interesting or relevant.\n",
    "Process the Data:\n",
    "\n",
    "# Convert the retrieved JSON data into a DataFrame using the pandas library.\n",
    "Perform basic data cleaning, such as removing null values or renaming columns.\n",
    "Save the Data:\n",
    "\n",
    "# Convert the cleaned data into a CSV or Parquet file format.\n",
    "Save the file to your local machine.\n",
    "Submit Your Work:\n",
    "\n",
    "# Push your project to a GitHub repository. Ensure the repository includes:\n",
    "A README.md file explaining the API you selected and the steps you followed.\n",
    "Your Python code in a well-commented script.\n",
    "The output file (CSV or Parquet) with the extracted data.\n",
    "Deliverables:\n",
    "\n",
    "# Link to your GitHub repository containing:\n",
    "Python script.\n",
    "CSV or Parquet file.\n",
    "README.md file with your project description.\n",
    "## Deadline:\n",
    "FRIDAY NOV 22ND 2024\n",
    "\n",
    "## Tips:\n",
    "\n",
    "Make sure the API you choose is free or provides a free tier for your usage.\n",
    "Test your API key (if required) and ensure your parameters are correct.\n",
    "Feel free to ask for help if you encounter any issues with API requests or data processing.\n",
    "Good luck! ðŸŽ‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE HERE\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
